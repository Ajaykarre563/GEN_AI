{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N4FkQj_XJmNp"
      },
      "source": [
        "# Fine tuning classification example\n",
        "\n",
        "We will fine-tune a `babbage-002` classifier (replacement for the `ada` models) to distinguish between the two sports: Baseball and Hockey."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Fine-tuning classification refers to the process of customizing a pre-trained model (like GPT or other machine learning models) to perform well on a specific classification task. In this context, the goal is to train the model to categorize inputs (e.g., text, images, or other data) into predefined labels or classes.**"
      ],
      "metadata": {
        "id": "iPtud2QGPkwg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Understanding Fine-Tuning for Classification**"
      ],
      "metadata": {
        "id": "l9Mn8g6ZP5Wp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pre-trained Models: Models like GPT and BERT are trained on large datasets to learn general patterns like language structure and relationships.\n",
        "\n",
        "Fine-Tuning: Fine-tuning specializes a pre-trained model by training it further on a smaller, task-specific dataset to adapt to the desired task.\n",
        "\n",
        "**Classification Tasks:**\n",
        "\n",
        "Classification tasks involve categorizing data into specific classes. Examples include:\n",
        "        \n",
        "Text Classification: Classifying emails as spam or not spam.\n",
        "        \n",
        "Sentiment Analysis: Determining whether a review is positive, negative, or neutral.\n",
        "        \n",
        "Topic Detection: Identifying the topic of an article (e.g., sports, technology, politics)."
      ],
      "metadata": {
        "id": "QdsYm-jNQExz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Email Spam Classification**\n",
        "\n",
        "Task: Categorize emails as either Spam or Not Spam.\n",
        "    \n",
        "Example:\n",
        "        \n",
        "Input: \"Congratulations! You've won a $1,000 gift card. Click the link to claim your prize!\"\n",
        "        \n",
        "Output: \"Spam\"\n",
        "\n",
        "2.**Sentiment Analysis**\n",
        "\n",
        "Task: Classify the sentiment of a review or comment as Positive, Negative, or Neutral.\n",
        "    \n",
        "Example:\n",
        "        \n",
        "Input: \"The product quality is excellent, and I’m very satisfied with the purchase!\"\n",
        "        \n",
        "Output: \"Positive\""
      ],
      "metadata": {
        "id": "7blezEPeRJOh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --quiet openai"
      ],
      "metadata": {
        "id": "RfD1eNptKQIM"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mkbZ3vbnKWCR",
        "outputId": "b32c3587-0fb1-4316-f916-fdfce186a33a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.54.4)\n",
            "Collecting openai\n",
            "  Downloading openai-1.55.0-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.27.2)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.7.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.9.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.6)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.23.4)\n",
            "Downloading openai-1.55.0-py3-none-any.whl (389 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m389.5/389.5 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: openai\n",
            "  Attempting uninstall: openai\n",
            "    Found existing installation: openai 1.54.4\n",
            "    Uninstalling openai-1.54.4:\n",
            "      Successfully uninstalled openai-1.54.4\n",
            "Successfully installed openai-1.55.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "uWA4vrllJmNt"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import fetch_20newsgroups\n",
        "import pandas as pd\n",
        "import openai\n",
        "import os\n",
        "\n",
        "#client = openai.OpenAI(api_key=os.environ.get(\"OPENAI_API_KEY\", \"<your OpenAI API key if not set as env var>\"))\n",
        "\n",
        "categories = ['rec.sport.baseball', 'rec.sport.hockey']\n",
        "sports_dataset = fetch_20newsgroups(subset='train', shuffle=True, random_state=42, categories=categories)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hGh8j1YbJmNv"
      },
      "source": [
        " ## Data exploration\n",
        " The newsgroup dataset can be loaded using sklearn. First we will look at the data itself:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5W885anVJmNw",
        "outputId": "ee8a56da-392f-4fab-d8c3-53bd5b99ab39"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "From: dougb@comm.mot.com (Doug Bank)\n",
            "Subject: Re: Info needed for Cleveland tickets\n",
            "Reply-To: dougb@ecs.comm.mot.com\n",
            "Organization: Motorola Land Mobile Products Sector\n",
            "Distribution: usa\n",
            "Nntp-Posting-Host: 145.1.146.35\n",
            "Lines: 17\n",
            "\n",
            "In article <1993Apr1.234031.4950@leland.Stanford.EDU>, bohnert@leland.Stanford.EDU (matthew bohnert) writes:\n",
            "\n",
            "|> I'm going to be in Cleveland Thursday, April 15 to Sunday, April 18.\n",
            "|> Does anybody know if the Tribe will be in town on those dates, and\n",
            "|> if so, who're they playing and if tickets are available?\n",
            "\n",
            "The tribe will be in town from April 16 to the 19th.\n",
            "There are ALWAYS tickets available! (Though they are playing Toronto,\n",
            "and many Toronto fans make the trip to Cleveland as it is easier to\n",
            "get tickets in Cleveland than in Toronto.  Either way, I seriously\n",
            "doubt they will sell out until the end of the season.)\n",
            "\n",
            "-- \n",
            "Doug Bank                       Private Systems Division\n",
            "dougb@ecs.comm.mot.com          Motorola Communications Sector\n",
            "dougb@nwu.edu                   Schaumburg, Illinois\n",
            "dougb@casbah.acns.nwu.edu       708-576-8207                    \n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(sports_dataset['data'][0])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sports_dataset['target_names']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s7XXgTPMKv00",
        "outputId": "30167c69-e33d-4bde-a72f-24e42577e84d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['rec.sport.baseball', 'rec.sport.hockey']"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "id": "mPqxjEwRJmNx",
        "outputId": "2a7c39d7-0de5-496f-e2b4-6e5c1ee87cd7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'rec.sport.baseball'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "sports_dataset.target_names[sports_dataset['target'][0]]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gsIkB-TdJmNy",
        "outputId": "b974caae-9656-425b-c45d-ddd15903002f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total examples: 1197, Baseball examples: 597, Hockey examples: 600\n"
          ]
        }
      ],
      "source": [
        "len_all, len_baseball, len_hockey = len(sports_dataset.data), len([e for e in sports_dataset.target if e == 0]), len([e for e in sports_dataset.target if e == 1])\n",
        "print(f\"Total examples: {len_all}, Baseball examples: {len_baseball}, Hockey examples: {len_hockey}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q8v0up3pJmNz"
      },
      "source": [
        "One sample from the baseball category can be seen above. It is an email to a mailing list. We can observe that we have 1197 examples in total, which are evenly split between the two sports."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SpleqgyMJmN0"
      },
      "source": [
        "## Data Preparation\n",
        "We transform the dataset into a pandas dataframe, with a column for prompt and completion. The prompt contains the email from the mailing list, and the completion is a name of the sport, either hockey or baseball. For demonstration purposes only and speed of fine-tuning we take only 300 examples. In a real use case the more examples the better the performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "H1yCPDqYJmN1",
        "outputId": "4c1a9d5c-7483-49b6-f858-5353f68d2b38"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              prompt completion\n",
              "0  From: dougb@comm.mot.com (Doug Bank)\\nSubject:...   baseball\n",
              "1  From: gld@cunixb.cc.columbia.edu (Gary L Dare)...     hockey\n",
              "2  From: rudy@netcom.com (Rudy Wade)\\nSubject: Re...   baseball\n",
              "3  From: monack@helium.gas.uug.arizona.edu (david...     hockey\n",
              "4  Subject: Let it be Known\\nFrom: <ISSBTL@BYUVM....   baseball"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6123d9e2-0882-4910-8554-b1d8dc21cf35\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>prompt</th>\n",
              "      <th>completion</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>From: dougb@comm.mot.com (Doug Bank)\\nSubject:...</td>\n",
              "      <td>baseball</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>From: gld@cunixb.cc.columbia.edu (Gary L Dare)...</td>\n",
              "      <td>hockey</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>From: rudy@netcom.com (Rudy Wade)\\nSubject: Re...</td>\n",
              "      <td>baseball</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>From: monack@helium.gas.uug.arizona.edu (david...</td>\n",
              "      <td>hockey</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Subject: Let it be Known\\nFrom: &lt;ISSBTL@BYUVM....</td>\n",
              "      <td>baseball</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6123d9e2-0882-4910-8554-b1d8dc21cf35')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6123d9e2-0882-4910-8554-b1d8dc21cf35 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6123d9e2-0882-4910-8554-b1d8dc21cf35');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-bcf5df7a-a920-49a6-a995-44e74e190351\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-bcf5df7a-a920-49a6-a995-44e74e190351')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-bcf5df7a-a920-49a6-a995-44e74e190351 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 1197,\n  \"fields\": [\n    {\n      \"column\": \"prompt\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1197,\n        \"samples\": [\n          \"From: dtate+@pitt.edu (David M. Tate)\\nSubject: Re: Braves Pitching UpdateDIR\\nOrganization: Department of Industrial Engineering\\nLines: 54\\n\\nsbp002@acad.drake.edu said:\\n\\n>> In article 2482@adobe.com, snichols@adobe.com (Sherri Nichols) writes:\\n>>>Every single piece of evidence we can find points to Major League Baseball\\n>>>being 50% offense, 50% defense.  A run scored is just as important as a run\\n>>>prevented.  \\n\\n>Of course a run scored is just as important as a run prevented.\\n>Just as a penny saved is a penny earned.  Enough with the cliches.\\n\\nIt's not a cliche, and (unlike your comments below) it's not a tautology.\\nIt needn't have been true.  If every pitcher in baseball were essentially\\nthe same in quality (i.e. if the variance of pitching ability were much\\nsmaller than the variance of batting ability), then scoring runs would be\\nmuch more important than preventing them, simply because the *ability* to\\nactively prevent runs would be much weaker.\\n\\n>My point is that IF the Braves starters are able to live up to\\n>their potential, they won't need much offensive support.\\n\\nIf that's your point, you should have said so.  What you in fact said was\\n\\\"Pitching and defense win championships\\\", and later \\\"Pitching is the essence\\nof baseball\\\".  Neither of which says what you are now claiming was \\\"your \\npoint\\\", and neither of which is true.\\n\\n>It seems to me that when quality pitchers take the\\n>mound, the other teams score less runs.  The team that scores the most \\n>runs wins.  \\n\\nAnd you accuse Sherri of mouthing cliches!?\\n\\n>This puts the team with the better pitching at the advantage\\n>(providing they can stop the opposing team from scoring runs).  A low \\n>scoring game would clearly benefit the Braves.  \\n\\nIt's not clear to me at all that this is true.  In high-scoring games, the\\nteam with the better offense wins a high percentage of the time.  In low-\\nscoring games, the split is essentially 50/50 regardless of team ability.\\n\\n>They should have many \\n>low scoring games due to their excellent pitching and below average hitting.\\n>On the flip side, if you had a starting lineup of great offensive players,\\n>I would be arguing that this team would not need great pitchers.\\n\\nI thought you said \\\"pitching and defense win championships\\\" and \\\"pitching is\\nthe essence of baseball\\\".\\n\\n\\n\\n-- \\n   David M. Tate   (dtate+@pitt.edu) |  Greetings, sir, with bat not quick \\n     member IIE, ORSA, TIMS, SABR    |  Hands not soft, eye not discerning\\n                                     |  And in Denver they call you a slugger?\\n   \\\"The Big Catullus\\\" Galarraga      |  And compare you to my own Mattingly!?\",\n          \"From: golchowy@alchemy.chem.utoronto.ca (Gerald Olchowy)\\nSubject: Re: Panther's President\\nOrganization: University of Toronto Chemistry Department\\nLines: 20\\n\\nIn article <0P6a3B1w165w@cybernet.cse.fau.edu> jimg@cybernet.cse.fau.edu (Jim Gorycki) writes:\\n>\\n>A little Bio from _Sun-Sentinel_\\n>Torrey, the architect of four consecutive Stanley Cup champions as \\n>persident and general manager of the New York Islanders.\\n>Throughout his 27 years in the NHL, Bill Torrey's bow ties have become\\n>as much of a signature as Andre Agassi's hair.\\n>\\n>The Panthers will introduce a uniform, insignia, and ticket-price \\n>information in early next month.  In the meantime, Huizenga leaves the\\n>day-to-day operation in the hands of Torrey and Bob Clarke, the VP and\\n>GM.\\n>\\n\\nThe San Jose Sharks and Ottawa Senators are each on their second GM\\nalready...I'd be willing to wager that both the Sharks and Senators\\nwill probably see their 3rd GM's and perhaps their 4th, before we\\nsee the Panthers second.\\n\\nGerald\",\n          \"From: kenney@tribe.b17d.ingr.COM (David Kenney)\\nSubject: My 1993 Predictions\\nReply-To: kenney@tribe.b17d.ingr.com\\nOrganization: Intergraph Corporation, Huntsville, Alabama\\nLines: 57\\n\\nI thought I'd post my predicted standings since I find those posted by others\\nto be interesting.  Sorry this is after Opening Day.  I certify that these\\nwere completed before the first pitch. :-)\\n\\nAL East\\n1.  New York Yankees - the most (only?) improved team in this division\\n2.  Toronto Blue Jays - Stewart and Morris?  No way.\\n3.  Milwaukee Brewers - they always seem to do better than I expect\\n4.  Baltimore Orioles - Pitching, but Devareaux, Anderson, and Hoiles will drop\\n5.  Cleveland Indians - Still don't seem to know what they are doing\\n6.  Detroit Tigers - All key players but Fryman are another year past peak\\n7.  Boston Red Sox - Any team with Clemens and Viola might be beter than 7th\\n\\nAl West - this division was the toughest for me to pick.  Whoever of the top\\n          4 gets pitching should win it.\\n1.  Minnesota Twins - young pitchers seem to have best chance for success\\n2.  Texas Rangers - I don't know why I have them here.  Jose Canseco?\\n3.  Chicago White Sox - Frank Thomas but no pitching.\\n4.  Oakland A's - LaRussa is the best manager and would keep any team close\\n5.  Seattle Mariners - I like Pinella, but don't see much here\\n6.  Kansas City Royals - will score no runs\\n7.  California Angels - will win no games\\n\\nNL East\\n1.  Montreal Expos - good all around, plus no Wallach!\\n2.  St. Louis Cardinals - (Jeffries + Whiten) >> (Jose + Clark), no Galarraga\\n3.  Pittsburgh Pirates - youngsters will take up more slack than expected\\n4.  New York Mets - some good players, still not a \\\"team\\\"\\n5.  Philadelphia Phillies - they don't impress me\\n6.  Florida Marlins - they know what they're doing\\n7.  Chicago Cubs - they don't know what they're doing\\n\\nNL West - The 2 best teams in baseball are in this division.\\n1.  Atlanta Braves - Awesome starters, but offense could be a concern\\n2.  Cincinnati Reds - Would not surprise me if they won it all\\n3.  Houston Astros - Any team that signs Uribe won't contend. Closer to 4 than 2\\n4.  San Diego Padres - Plantier could be the Sheffield of 1993\\n5.  Los Angeles Dodgers - better pitching than the Giants\\n6.  San Francisco Giants - because the Rockies just stink\\n7.  Colorado Rockies - will become the Seattle Mariners of the NL.\\n\\n\\nNLCS  Montreal d. Atlanta  (Braves fans, yes I'm probably contradicting\\n                            what I said in my NL West comment.)\\nALCS  New York d. Minnesota\\n\\nWorld Series  New York d. Montreal - Hating the Yankees will be\\n                                     fashionable again\\n\\nNL MVP:  Barry Bonds, or maybe McGriff\\nNL Cy Young:  Jose Rijo\\nAL MVP:  Frank Thomas will deserve it (again), but Fielder might win it\\nAL Cy Young:  Roger Clemens (at least will deserve it (again))\\n\\n-- \\n-------------------------------------------------------------------------------\\nDavid Kenney                                       kenney@tribe.b17d.ingr.com\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"completion\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"hockey\",\n          \"baseball\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "labels = [sports_dataset.target_names[x].split('.')[-1] for x in sports_dataset['target']]\n",
        "texts = [text.strip() for text in sports_dataset['data']]\n",
        "df = pd.DataFrame(zip(texts, labels), columns = ['prompt','completion']) #[:300]\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WGii4qO8JmN3"
      },
      "source": [
        "Both baseball and hockey are single tokens. We save the dataset as a jsonl file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "pwVeKvC-JmN3"
      },
      "outputs": [],
      "source": [
        "df.to_json(\"sport2.jsonl\", orient='records', lines=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M70C3tVoJmN4"
      },
      "source": [
        "### Data Preparation tool\n",
        "We can now use a data preparation tool which will suggest a few improvements to our dataset before fine-tuning. Before launching the tool we update the openai library to ensure we're using the latest data preparation tool. We additionally specify `-q` which auto-accepts all suggestions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FN_rb7kyJmN5",
        "outputId": "4dd5a243-c043-4bce-fd27-38fda7079a3f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Analyzing...\n",
            "\n",
            "- Your file contains 1197 prompt-completion pairs\n",
            "- Based on your data it seems like you're trying to fine-tune a model for classification\n",
            "- For classification, we recommend you try one of the faster and cheaper models, such as `ada`\n",
            "- For classification, you can estimate the expected model performance by keeping a held out dataset, which is not used for training\n",
            "- There are 11 examples that are very long. These are rows: [134, 200, 281, 320, 404, 595, 704, 838, 1113, 1139, 1174]\n",
            "For conditional generation, and for classification the examples shouldn't be longer than 2048 tokens.\n",
            "- Your data does not contain a common separator at the end of your prompts. Having a separator string appended to the end of the prompt makes it clearer to the fine-tuned model where the completion should begin. See https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset for more detail and examples. If you intend to do open-ended generation, then you should leave the prompts empty\n",
            "- The completion should start with a whitespace character (` `). This tends to produce better results due to the tokenization we use. See https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset for more details\n",
            "\n",
            "Based on the analysis we will perform the following actions:\n",
            "- [Recommended] Remove 11 long examples [Y/n]: Y\n",
            "- [Recommended] Add a suffix separator `\\n\\n###\\n\\n` to all prompts [Y/n]: Y\n",
            "- [Recommended] Add a whitespace character to the beginning of the completion [Y/n]: Y\n",
            "- [Recommended] Would you like to split into training and validation set? [Y/n]: Y\n",
            "\n",
            "\n",
            "Your data will be written to a new JSONL file. Proceed [Y/n]: Y\n",
            "\n",
            "Wrote modified files to `sport2_prepared_train (1).jsonl` and `sport2_prepared_valid (1).jsonl`\n",
            "Feel free to take a look!\n",
            "\n",
            "Now use that file when fine-tuning:\n",
            "> openai api fine_tunes.create -t \"sport2_prepared_train (1).jsonl\" -v \"sport2_prepared_valid (1).jsonl\" --compute_classification_metrics --classification_positive_class \" baseball\"\n",
            "\n",
            "After you’ve fine-tuned a model, remember that your prompt has to end with the indicator string `\\n\\n###\\n\\n` for the model to start generating completions, rather than continuing with the prompt.\n",
            "Once your model starts training, it'll approximately take 30.8 minutes to train a `curie` model, and less for `ada` and `babbage`. Queue will approximately take half an hour per job ahead of you.\n"
          ]
        }
      ],
      "source": [
        "!openai tools fine_tunes.prepare_data -f sport2.jsonl -q"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f7hZhz-dJmN6"
      },
      "source": [
        "The tool helpfully suggests a few improvements to the dataset and splits the dataset into training and validation set.\n",
        "\n",
        "A suffix between a prompt and a completion is necessary to tell the model that the input text has stopped, and that it now needs to predict the class. Since we use the same separator in each example, the model is able to learn that it is meant to predict either baseball or hockey following the separator.\n",
        "A whitespace prefix in completions is useful, as most word tokens are tokenized with a space prefix.\n",
        "The tool also recognized that this is likely a classification task, so it suggested to split the dataset into training and validation datasets. This will allow us to easily measure expected performance on new data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y4KzsN9UJmN6"
      },
      "source": [
        "## Fine-tuning\n",
        "The tool suggests we run the following command to train the dataset. Since this is a classification task, we would like to know what the generalization performance on the provided validation set is for our classification use case.\n",
        "\n",
        "We can simply copy the suggested command from the CLI tool. We specifically add `-m ada` to fine-tune a cheaper and faster ada model, which is usually comperable in performance to slower and more expensive models on classification use cases."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EoXERBhpM6VQ",
        "outputId": "a71423ca-af38-4497-fd28-856ce0f270da"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " \u001b[0m\u001b[01;34msample_data\u001b[0m/  'sport2_prepared_train (1).jsonl'  'sport2_prepared_valid (1).jsonl'\n",
            " sport2.jsonl   sport2_prepared_train.jsonl        sport2_prepared_valid.jsonl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "\n",
        "# Set API key\n",
        "openai.api_key = \"your_actual_api_key\""
      ],
      "metadata": {
        "id": "ueIT2hmhNCXx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WpqLOXVwJmN7"
      },
      "source": [
        "The model is successfully trained in about ten minutes. You can watch the finetune happen on [https://platform.openai.com/finetune/](https://platform.openai.com/finetune/)\n",
        "\n",
        "You can also check on its status programatically:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Upload training and validation files\n",
        "train_file = client.files.create(file=open(\"sport2_prepared_train.jsonl\", \"rb\"), purpose=\"fine-tune\")\n",
        "valid_file = client.files.create(file=open(\"sport2_prepared_valid.jsonl\", \"rb\"), purpose=\"fine-tune\")\n",
        "\n",
        "# Start fine-tuning job\n",
        "fine_tuning_job = client.fine_tuning.jobs.create(training_file=train_file.id, validation_file=valid_file.id, model=\"babbage-002\")\n",
        "\n",
        "print(fine_tuning_job)"
      ],
      "metadata": {
        "id": "NiBypnLRM0gl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3bLbY1uNJmN8",
        "outputId": "90c5a2f2-9499-4c18-8487-02a595368bb6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1704414393\n"
          ]
        }
      ],
      "source": [
        "fine_tune_results = client.fine_tuning.jobs.retrieve(fine_tuning_job.id)\n",
        "print(fine_tune_results.finished_at)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z0bYDn7mJmN9"
      },
      "source": [
        "### [Advanced] Results and expected model performance\n",
        "We can now download the results file to observe the expected performance on a held out validation set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ewGOFfwSJmN9"
      },
      "outputs": [],
      "source": [
        "fine_tune_results = client.fine_tuning.jobs.retrieve(fine_tuning_job.id).result_files\n",
        "result_file = client.files.retrieve(fine_tune_results[0])\n",
        "content = client.files.content(result_file.id)\n",
        "# save content to file\n",
        "with open(\"result.csv\", \"wb\") as f:\n",
        "    f.write(content.text.encode(\"utf-8\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AutIbSp3JmN9",
        "outputId": "5887682b-8e13-45fc-ccdf-ff6161df5d56"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>step</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>train_accuracy</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>valid_mean_token_accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2843</th>\n",
              "      <td>2844</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      step  train_loss  train_accuracy  valid_loss  valid_mean_token_accuracy\n",
              "2843  2844         0.0             1.0         NaN                        NaN"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "results = pd.read_csv('result.csv')\n",
        "results[results['train_accuracy'].notnull()].tail(1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l-RcevMvJmN-"
      },
      "source": [
        "The accuracy reaches 99.6%. On the plot below we can see how accuracy on the validation set increases during the training run."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tqgYvGP3JmN-"
      },
      "outputs": [],
      "source": [
        "results[results['train_accuracy'].notnull()]['train_accuracy'].plot()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ESFrUw9bJmN_"
      },
      "source": [
        "## Using the model\n",
        "We can now call the model to get the predictions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V8RFzuFuJmN_",
        "outputId": "ccde46fd-df74-4679-9f17-547c756abc38"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>prompt</th>\n",
              "      <th>completion</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>From: gld@cunixb.cc.columbia.edu (Gary L Dare)...</td>\n",
              "      <td>hockey</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>From: smorris@venus.lerc.nasa.gov (Ron Morris ...</td>\n",
              "      <td>hockey</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>From: golchowy@alchemy.chem.utoronto.ca (Geral...</td>\n",
              "      <td>hockey</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>From: krattige@hpcc01.corp.hp.com (Kim Krattig...</td>\n",
              "      <td>baseball</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>From: warped@cs.montana.edu (Doug Dolven)\\nSub...</td>\n",
              "      <td>baseball</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              prompt completion\n",
              "0  From: gld@cunixb.cc.columbia.edu (Gary L Dare)...     hockey\n",
              "1  From: smorris@venus.lerc.nasa.gov (Ron Morris ...     hockey\n",
              "2  From: golchowy@alchemy.chem.utoronto.ca (Geral...     hockey\n",
              "3  From: krattige@hpcc01.corp.hp.com (Kim Krattig...   baseball\n",
              "4  From: warped@cs.montana.edu (Doug Dolven)\\nSub...   baseball"
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test = pd.read_json('sport2_prepared_valid.jsonl', lines=True)\n",
        "test.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_-FepQP9JmOA"
      },
      "source": [
        "We need to use the same separator following the prompt which we used during fine-tuning. In this case it is `\\n\\n###\\n\\n`. Since we're concerned with classification, we want the temperature to be as low as possible, and we only require one token completion to determine the prediction of the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dncDhLzdJmOA",
        "outputId": "7a86b204-4fd9-44d2-cd1c-8c11d54d31f0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "' hockey'"
            ]
          },
          "execution_count": 69,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ft_model = fine_tune_results.fine_tuned_model\n",
        "\n",
        "# note that this calls the legacy completions api - https://platform.openai.com/docs/api-reference/completions\n",
        "res = client.completions.create(model=ft_model, prompt=test['prompt'][0] + '\\n\\n###\\n\\n', max_tokens=1, temperature=0)\n",
        "res.choices[0].text\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5W1jeSdTJmOB"
      },
      "source": [
        "To get the log probabilities, we can specify logprobs parameter on the completion request"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JRIsVBcUJmOB",
        "outputId": "3ae6b768-f415-4547-91e8-ff506acf8bac"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{' hockey': 0.0, ' Hockey': -22.504879}]"
            ]
          },
          "execution_count": 71,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "res = client.completions.create(model=ft_model, prompt=test['prompt'][0] + '\\n\\n###\\n\\n', max_tokens=1, temperature=0, logprobs=2)\n",
        "res.choices[0].logprobs.top_logprobs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "speUISkRJmOC"
      },
      "source": [
        "We can see that the model predicts hockey as a lot more likely than baseball, which is the correct prediction. By requesting log_probs, we can see the prediction (log) probability for each class."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1vtoJfyyJmOD"
      },
      "source": [
        "### Generalization\n",
        "Interestingly, our fine-tuned classifier is quite versatile. Despite being trained on emails to different mailing lists, it also successfully predicts tweets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zkSXTWc-JmOD",
        "outputId": "319e6038-ec6c-409c-86bf-67ad6be1800d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "' hockey'"
            ]
          },
          "execution_count": 73,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sample_hockey_tweet = \"\"\"Thank you to the\n",
        "@Canes\n",
        " and all you amazing Caniacs that have been so supportive! You guys are some of the best fans in the NHL without a doubt! Really excited to start this new chapter in my career with the\n",
        "@DetroitRedWings\n",
        " !!\"\"\"\n",
        "res = client.completions.create(model=ft_model, prompt=sample_hockey_tweet + '\\n\\n###\\n\\n', max_tokens=1, temperature=0, logprobs=2)\n",
        "res.choices[0].text"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_baseball_tweet=\"\"\"BREAKING: The Tampa Bay Rays are finalizing a deal to acquire slugger Nelson Cruz from the Minnesota Twins, sources tell ESPN.\"\"\"\n",
        "res = client.completions.create(model=ft_model, prompt=sample_baseball_tweet + '\\n\\n###\\n\\n', max_tokens=1, temperature=0, logprobs=2)\n",
        "res.choices[0].text"
      ],
      "metadata": {
        "id": "6DqY8aoORbSw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **NOTE: HOW IT IS CLASSIFIER WHERE IT A HOCKEY OR BASEBALL.**\n",
        "\n",
        "1. **Keywords and Terms**\n",
        "\n",
        "    The tweet includes baseball-specific terms like:\n",
        "        \"slugger\" (a term commonly used in baseball for a powerful hitter).\n",
        "        Names of MLB teams: \"Tampa Bay Rays\" and \"Minnesota Twins\".\n",
        "    These terms strongly associate with baseball, as they are part of its unique terminology.\n",
        "\n",
        "2. **Lack of Hockey-Specific Terms**\n",
        "\n",
        "    The tweet does not mention any hockey-specific elements such as:\n",
        "        NHL team names.\n",
        "        Hockey-related terminology like \"puck\", \"goal\", or \"NHL\".\n",
        "    The absence of hockey-related terms helps the model exclude Hockey as a label.\n",
        "\n",
        "3. **Pre-trained Patterns from Fine-Tuning**\n",
        "\n",
        "    During fine-tuning, the model learns the association of teams like Tampa Bay Rays and Minnesota Twins with baseball.\n",
        "    Similarly, it learns that phrases like \"acquire slugger\" commonly occur in the context of baseball trades, not hockey.\n",
        "\n",
        "4. **Contextual Knowledge**\n",
        "\n",
        "    Baseball involves frequent trades and acquisitions of players, especially with terms like \"slugger\" or \"deal\".\n",
        "    The model leverages its general knowledge to understand that this scenario fits the context of baseball.\n",
        "\n",
        "5. **Conclusion**\n",
        "\n",
        "The classifier correctly labels the tweet as Baseball based on the presence of team names, terminology, and context learned during fine-tuning. The absence of hockey-related clues further reinforces the choice.\n"
      ],
      "metadata": {
        "id": "pQ3UHzIzS7YW"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7WsD1Tt8TNRJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "3b138a8faad971cc852f62bcf00f59ea0e31721743ea2c5a866ca26adf572e75"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}