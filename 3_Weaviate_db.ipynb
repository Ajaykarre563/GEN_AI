{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Weaviate**\n",
        "\n",
        "Weaviate is an open-source vector database designed to store, manage, and retrieve data represented as vectors. It enables efficient and scalable similarity searches, making it ideal for working with applications powered by machine learning models or other systems that use vector representations."
      ],
      "metadata": {
        "id": "VSlQQTb46yTA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Top 3 Use Cases for Weaviate:**\n",
        "\n",
        "**Semantic Search:** Enables context-based search for documents, products, or data, beyond simple keyword matching.\n",
        "    \n",
        "**Recommendation Systems:** Delivers personalized suggestions by comparing user preferences and item embeddings.\n",
        "    \n",
        "**Generative AI Applications:** Acts as a memory layer for AI chatbots and assistants to store and retrieve embeddings efficiently."
      ],
      "metadata": {
        "id": "i_eCToUM7K9c"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t26J2nX6B2AH"
      },
      "source": [
        "https://console.weaviate.cloud/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jnIh-coaAGnU",
        "outputId": "b75cd53e-1c3e-4048-de71-a30d32d5140f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting weaviate-client\n",
            "  Downloading weaviate_client-4.9.4-py3-none-any.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.30.0 in /usr/local/lib/python3.10/dist-packages (from weaviate-client) (2.32.3)\n",
            "Collecting httpx<=0.27.0,>=0.25.0 (from weaviate-client)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl.metadata (7.2 kB)\n",
            "Collecting validators==0.34.0 (from weaviate-client)\n",
            "  Downloading validators-0.34.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting authlib<1.3.2,>=1.2.1 (from weaviate-client)\n",
            "  Downloading Authlib-1.3.1-py2.py3-none-any.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from weaviate-client) (2.9.2)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.57.0 in /usr/local/lib/python3.10/dist-packages (from weaviate-client) (1.68.0)\n",
            "Collecting grpcio-tools<2.0.0,>=1.57.0 (from weaviate-client)\n",
            "  Downloading grpcio_tools-1.68.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.3 kB)\n",
            "Collecting grpcio-health-checking<2.0.0,>=1.57.0 (from weaviate-client)\n",
            "  Downloading grpcio_health_checking-1.68.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: cryptography in /usr/local/lib/python3.10/dist-packages (from authlib<1.3.2,>=1.2.1->weaviate-client) (43.0.3)\n",
            "Collecting protobuf<6.0dev,>=5.26.1 (from grpcio-health-checking<2.0.0,>=1.57.0->weaviate-client)\n",
            "  Downloading protobuf-5.28.3-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from grpcio-tools<2.0.0,>=1.57.0->weaviate-client) (75.1.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<=0.27.0,>=0.25.0->weaviate-client) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<=0.27.0,>=0.25.0->weaviate-client) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<=0.27.0,>=0.25.0->weaviate-client) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx<=0.27.0,>=0.25.0->weaviate-client) (3.10)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<=0.27.0,>=0.25.0->weaviate-client) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<=0.27.0,>=0.25.0->weaviate-client) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.5.0->weaviate-client) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.5.0->weaviate-client) (2.23.4)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.5.0->weaviate-client) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.30.0->weaviate-client) (3.4.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.30.0->weaviate-client) (2.2.3)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<=0.27.0,>=0.25.0->weaviate-client) (1.2.2)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography->authlib<1.3.2,>=1.2.1->weaviate-client) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography->authlib<1.3.2,>=1.2.1->weaviate-client) (2.22)\n",
            "Downloading weaviate_client-4.9.4-py3-none-any.whl (386 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m387.0/387.0 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading validators-0.34.0-py3-none-any.whl (43 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.5/43.5 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Authlib-1.3.1-py2.py3-none-any.whl (223 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m223.8/223.8 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading grpcio_health_checking-1.68.0-py3-none-any.whl (18 kB)\n",
            "Downloading grpcio_tools-1.68.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m35.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading protobuf-5.28.3-cp38-abi3-manylinux2014_x86_64.whl (316 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.6/316.6 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: validators, protobuf, httpx, grpcio-tools, grpcio-health-checking, authlib, weaviate-client\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 4.25.5\n",
            "    Uninstalling protobuf-4.25.5:\n",
            "      Successfully uninstalled protobuf-4.25.5\n",
            "  Attempting uninstall: httpx\n",
            "    Found existing installation: httpx 0.27.2\n",
            "    Uninstalling httpx-0.27.2:\n",
            "      Successfully uninstalled httpx-0.27.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.17.1 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 5.28.3 which is incompatible.\n",
            "tensorflow-metadata 1.13.1 requires protobuf<5,>=3.20.3, but you have protobuf 5.28.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed authlib-1.3.1 grpcio-health-checking-1.68.0 grpcio-tools-1.68.0 httpx-0.27.0 protobuf-5.28.3 validators-0.34.0 weaviate-client-4.9.4\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.3.7)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.36)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.11.2)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.15 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.19)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.2)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.143)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.26.4)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.9.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (9.0.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (0.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.17.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain) (4.12.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (0.27.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.11)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.23.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.8.30)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.0.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.15->langchain) (3.0.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.2.2)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.54.4)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.27.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.7.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.9.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.6)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.23.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install weaviate-client\n",
        "!pip install langchain\n",
        "!pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V-sQraYtBvBv"
      },
      "outputs": [],
      "source": [
        "OPENAI_API_KEY = \"\"\n",
        "WEAVIATE_API_KEY = \"\"\n",
        "WEAVIATE_CLUSTER = \"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uuytDEGdCyCl"
      },
      "source": [
        "## Data Reading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "UBGcj0bxCwgO"
      },
      "outputs": [],
      "source": [
        "!mkdir data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Vzf37wCDEHom",
        "outputId": "b669b9a1-2437-4685-8a56-ae5d75900c41"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting unstructured\n",
            "  Downloading unstructured-0.16.8-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: chardet in /usr/local/lib/python3.10/dist-packages (from unstructured) (5.2.0)\n",
            "Collecting filetype (from unstructured)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting python-magic (from unstructured)\n",
            "  Downloading python_magic-0.4.27-py2.py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from unstructured) (5.3.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from unstructured) (3.9.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from unstructured) (2.32.3)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from unstructured) (4.12.3)\n",
            "Collecting emoji (from unstructured)\n",
            "  Downloading emoji-2.14.0-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting dataclasses-json (from unstructured)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting python-iso639 (from unstructured)\n",
            "  Downloading python_iso639-2024.10.22-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting langdetect (from unstructured)\n",
            "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m26.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy<2 in /usr/local/lib/python3.10/dist-packages (from unstructured) (1.26.4)\n",
            "Collecting rapidfuzz (from unstructured)\n",
            "  Downloading rapidfuzz-3.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Collecting backoff (from unstructured)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from unstructured) (4.12.2)\n",
            "Collecting unstructured-client (from unstructured)\n",
            "  Downloading unstructured_client-0.28.1-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from unstructured) (1.16.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from unstructured) (4.66.6)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from unstructured) (5.9.5)\n",
            "Collecting python-oxmsg (from unstructured)\n",
            "  Downloading python_oxmsg-0.0.1-py3-none-any.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: html5lib in /usr/local/lib/python3.10/dist-packages (from unstructured) (1.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->unstructured) (2.6)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json->unstructured)\n",
            "  Downloading marshmallow-3.23.1-py3-none-any.whl.metadata (7.5 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json->unstructured)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.10/dist-packages (from html5lib->unstructured) (1.16.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from html5lib->unstructured) (0.5.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->unstructured) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->unstructured) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->unstructured) (2024.9.11)\n",
            "Collecting olefile (from python-oxmsg->unstructured)\n",
            "  Downloading olefile-0.47-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->unstructured) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->unstructured) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->unstructured) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->unstructured) (2024.8.30)\n",
            "Collecting aiofiles>=24.1.0 (from unstructured-client->unstructured)\n",
            "  Downloading aiofiles-24.1.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: cryptography>=3.1 in /usr/local/lib/python3.10/dist-packages (from unstructured-client->unstructured) (43.0.3)\n",
            "Requirement already satisfied: eval-type-backport<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from unstructured-client->unstructured) (0.2.0)\n",
            "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.10/dist-packages (from unstructured-client->unstructured) (0.27.0)\n",
            "Collecting jsonpath-python<2.0.0,>=1.0.6 (from unstructured-client->unstructured)\n",
            "  Downloading jsonpath_python-1.0.6-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: nest-asyncio>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from unstructured-client->unstructured) (1.6.0)\n",
            "Requirement already satisfied: pydantic<2.10.0,>=2.9.2 in /usr/local/lib/python3.10/dist-packages (from unstructured-client->unstructured) (2.9.2)\n",
            "Collecting pypdf>=4.0 (from unstructured-client->unstructured)\n",
            "  Downloading pypdf-5.1.0-py3-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from unstructured-client->unstructured) (2.8.2)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from unstructured-client->unstructured) (1.0.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=3.1->unstructured-client->unstructured) (1.17.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->unstructured-client->unstructured) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->unstructured-client->unstructured) (1.0.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->unstructured-client->unstructured) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.27.0->unstructured-client->unstructured) (0.14.0)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->unstructured) (24.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<2.10.0,>=2.9.2->unstructured-client->unstructured) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<2.10.0,>=2.9.2->unstructured-client->unstructured) (2.23.4)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json->unstructured)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=3.1->unstructured-client->unstructured) (2.22)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.27.0->unstructured-client->unstructured) (1.2.2)\n",
            "Downloading unstructured-0.16.8-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m47.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading emoji-2.14.0-py3-none-any.whl (586 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m586.9/586.9 kB\u001b[0m \u001b[31m25.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Downloading python_iso639-2024.10.22-py3-none-any.whl (274 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m274.9/274.9 kB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_magic-0.4.27-py2.py3-none-any.whl (13 kB)\n",
            "Downloading python_oxmsg-0.0.1-py3-none-any.whl (31 kB)\n",
            "Downloading rapidfuzz-3.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m58.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading unstructured_client-0.28.1-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.9/62.9 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiofiles-24.1.0-py3-none-any.whl (15 kB)\n",
            "Downloading jsonpath_python-1.0.6-py3-none-any.whl (7.6 kB)\n",
            "Downloading marshmallow-3.23.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.5/49.5 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pypdf-5.1.0-py3-none-any.whl (297 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m298.0/298.0 kB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading olefile-0.47-py2.py3-none-any.whl (114 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.6/114.6 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Building wheels for collected packages: langdetect\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993222 sha256=dd6bcdc9a62d587765463d8ffa98525fc4d534bfef32cb48a87b3bd3118d4d0c\n",
            "  Stored in directory: /root/.cache/pip/wheels/95/03/7d/59ea870c70ce4e5a370638b5462a7711ab78fba2f655d05106\n",
            "Successfully built langdetect\n",
            "Installing collected packages: filetype, rapidfuzz, python-magic, python-iso639, pypdf, olefile, mypy-extensions, marshmallow, langdetect, jsonpath-python, emoji, backoff, aiofiles, typing-inspect, python-oxmsg, unstructured-client, dataclasses-json, unstructured\n",
            "Successfully installed aiofiles-24.1.0 backoff-2.2.1 dataclasses-json-0.6.7 emoji-2.14.0 filetype-1.2.0 jsonpath-python-1.0.6 langdetect-1.0.9 marshmallow-3.23.1 mypy-extensions-1.0.0 olefile-0.47 pypdf-5.1.0 python-iso639-2024.10.22 python-magic-0.4.27 python-oxmsg-0.0.1 rapidfuzz-3.10.1 typing-inspect-0.9.0 unstructured-0.16.8 unstructured-client-0.28.1\n",
            "Requirement already satisfied: unstructured[pdf] in /usr/local/lib/python3.10/dist-packages (0.16.8)\n",
            "Requirement already satisfied: chardet in /usr/local/lib/python3.10/dist-packages (from unstructured[pdf]) (5.2.0)\n",
            "Requirement already satisfied: filetype in /usr/local/lib/python3.10/dist-packages (from unstructured[pdf]) (1.2.0)\n",
            "Requirement already satisfied: python-magic in /usr/local/lib/python3.10/dist-packages (from unstructured[pdf]) (0.4.27)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from unstructured[pdf]) (5.3.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from unstructured[pdf]) (3.9.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from unstructured[pdf]) (2.32.3)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from unstructured[pdf]) (4.12.3)\n",
            "Requirement already satisfied: emoji in /usr/local/lib/python3.10/dist-packages (from unstructured[pdf]) (2.14.0)\n",
            "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.10/dist-packages (from unstructured[pdf]) (0.6.7)\n",
            "Requirement already satisfied: python-iso639 in /usr/local/lib/python3.10/dist-packages (from unstructured[pdf]) (2024.10.22)\n",
            "Requirement already satisfied: langdetect in /usr/local/lib/python3.10/dist-packages (from unstructured[pdf]) (1.0.9)\n",
            "Requirement already satisfied: numpy<2 in /usr/local/lib/python3.10/dist-packages (from unstructured[pdf]) (1.26.4)\n",
            "Requirement already satisfied: rapidfuzz in /usr/local/lib/python3.10/dist-packages (from unstructured[pdf]) (3.10.1)\n",
            "Requirement already satisfied: backoff in /usr/local/lib/python3.10/dist-packages (from unstructured[pdf]) (2.2.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from unstructured[pdf]) (4.12.2)\n",
            "Requirement already satisfied: unstructured-client in /usr/local/lib/python3.10/dist-packages (from unstructured[pdf]) (0.28.1)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from unstructured[pdf]) (1.16.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from unstructured[pdf]) (4.66.6)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from unstructured[pdf]) (5.9.5)\n",
            "Requirement already satisfied: python-oxmsg in /usr/local/lib/python3.10/dist-packages (from unstructured[pdf]) (0.0.1)\n",
            "Requirement already satisfied: html5lib in /usr/local/lib/python3.10/dist-packages (from unstructured[pdf]) (1.1)\n",
            "Collecting onnx (from unstructured[pdf])\n",
            "  Downloading onnx-1.17.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n",
            "Collecting pdf2image (from unstructured[pdf])\n",
            "  Downloading pdf2image-1.17.0-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting pdfminer.six (from unstructured[pdf])\n",
            "  Downloading pdfminer.six-20240706-py3-none-any.whl.metadata (4.1 kB)\n",
            "Collecting pikepdf (from unstructured[pdf])\n",
            "  Downloading pikepdf-9.4.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.2 kB)\n",
            "Collecting pi-heif (from unstructured[pdf])\n",
            "  Downloading pi_heif-0.20.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: pypdf in /usr/local/lib/python3.10/dist-packages (from unstructured[pdf]) (5.1.0)\n",
            "Collecting google-cloud-vision (from unstructured[pdf])\n",
            "  Downloading google_cloud_vision-3.8.1-py2.py3-none-any.whl.metadata (5.3 kB)\n",
            "Collecting effdet (from unstructured[pdf])\n",
            "  Downloading effdet-0.4.1-py3-none-any.whl.metadata (33 kB)\n",
            "Collecting unstructured-inference==0.8.1 (from unstructured[pdf])\n",
            "  Downloading unstructured_inference-0.8.1-py3-none-any.whl.metadata (5.9 kB)\n",
            "Collecting unstructured.pytesseract>=0.3.12 (from unstructured[pdf])\n",
            "  Downloading unstructured.pytesseract-0.3.13-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting layoutparser (from unstructured-inference==0.8.1->unstructured[pdf])\n",
            "  Downloading layoutparser-0.3.4-py3-none-any.whl.metadata (7.7 kB)\n",
            "Collecting python-multipart (from unstructured-inference==0.8.1->unstructured[pdf])\n",
            "  Downloading python_multipart-0.0.17-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from unstructured-inference==0.8.1->unstructured[pdf]) (0.26.2)\n",
            "Requirement already satisfied: opencv-python!=4.7.0.68 in /usr/local/lib/python3.10/dist-packages (from unstructured-inference==0.8.1->unstructured[pdf]) (4.10.0.84)\n",
            "Collecting onnxruntime>=1.17.0 (from unstructured-inference==0.8.1->unstructured[pdf])\n",
            "  Downloading onnxruntime-1.20.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from unstructured-inference==0.8.1->unstructured[pdf]) (3.8.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from unstructured-inference==0.8.1->unstructured[pdf]) (2.5.1+cu121)\n",
            "Requirement already satisfied: timm in /usr/local/lib/python3.10/dist-packages (from unstructured-inference==0.8.1->unstructured[pdf]) (1.0.11)\n",
            "Requirement already satisfied: transformers>=4.25.1 in /usr/local/lib/python3.10/dist-packages (from unstructured-inference==0.8.1->unstructured[pdf]) (4.46.2)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from unstructured.pytesseract>=0.3.12->unstructured[pdf]) (24.2)\n",
            "Requirement already satisfied: Pillow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from unstructured.pytesseract>=0.3.12->unstructured[pdf]) (11.0.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->unstructured[pdf]) (2.6)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json->unstructured[pdf]) (3.23.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json->unstructured[pdf]) (0.9.0)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from effdet->unstructured[pdf]) (0.20.1+cu121)\n",
            "Requirement already satisfied: pycocotools>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from effdet->unstructured[pdf]) (2.0.8)\n",
            "Collecting omegaconf>=2.0 (from effdet->unstructured[pdf])\n",
            "  Downloading omegaconf-2.3.0-py3-none-any.whl.metadata (3.9 kB)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-vision->unstructured[pdf]) (2.19.2)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1 in /usr/local/lib/python3.10/dist-packages (from google-cloud-vision->unstructured[pdf]) (2.27.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from google-cloud-vision->unstructured[pdf]) (1.25.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from google-cloud-vision->unstructured[pdf]) (5.28.3)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.10/dist-packages (from html5lib->unstructured[pdf]) (1.16.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from html5lib->unstructured[pdf]) (0.5.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->unstructured[pdf]) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->unstructured[pdf]) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->unstructured[pdf]) (2024.9.11)\n",
            "Requirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six->unstructured[pdf]) (3.4.0)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six->unstructured[pdf]) (43.0.3)\n",
            "Requirement already satisfied: Deprecated in /usr/local/lib/python3.10/dist-packages (from pikepdf->unstructured[pdf]) (1.2.15)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.10/dist-packages (from python-oxmsg->unstructured[pdf]) (0.47)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->unstructured[pdf]) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->unstructured[pdf]) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->unstructured[pdf]) (2024.8.30)\n",
            "Requirement already satisfied: aiofiles>=24.1.0 in /usr/local/lib/python3.10/dist-packages (from unstructured-client->unstructured[pdf]) (24.1.0)\n",
            "Requirement already satisfied: eval-type-backport<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from unstructured-client->unstructured[pdf]) (0.2.0)\n",
            "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.10/dist-packages (from unstructured-client->unstructured[pdf]) (0.27.0)\n",
            "Requirement already satisfied: jsonpath-python<2.0.0,>=1.0.6 in /usr/local/lib/python3.10/dist-packages (from unstructured-client->unstructured[pdf]) (1.0.6)\n",
            "Requirement already satisfied: nest-asyncio>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from unstructured-client->unstructured[pdf]) (1.6.0)\n",
            "Requirement already satisfied: pydantic<2.10.0,>=2.9.2 in /usr/local/lib/python3.10/dist-packages (from unstructured-client->unstructured[pdf]) (2.9.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from unstructured-client->unstructured[pdf]) (2.8.2)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from unstructured-client->unstructured[pdf]) (1.0.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=36.0.0->pdfminer.six->unstructured[pdf]) (1.17.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-vision->unstructured[pdf]) (1.66.0)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-vision->unstructured[pdf]) (1.68.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-vision->unstructured[pdf]) (1.62.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-vision->unstructured[pdf]) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-vision->unstructured[pdf]) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-vision->unstructured[pdf]) (4.9)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->unstructured-client->unstructured[pdf]) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->unstructured-client->unstructured[pdf]) (1.0.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->unstructured-client->unstructured[pdf]) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.27.0->unstructured-client->unstructured[pdf]) (0.14.0)\n",
            "Collecting antlr4-python3-runtime==4.9.* (from omegaconf>=2.0->effdet->unstructured[pdf])\n",
            "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: PyYAML>=5.1.0 in /usr/local/lib/python3.10/dist-packages (from omegaconf>=2.0->effdet->unstructured[pdf]) (6.0.2)\n",
            "Collecting coloredlogs (from onnxruntime>=1.17.0->unstructured-inference==0.8.1->unstructured[pdf])\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.17.0->unstructured-inference==0.8.1->unstructured[pdf]) (24.3.25)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.17.0->unstructured-inference==0.8.1->unstructured[pdf]) (1.13.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->unstructured-inference==0.8.1->unstructured[pdf]) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->unstructured-inference==0.8.1->unstructured[pdf]) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->unstructured-inference==0.8.1->unstructured[pdf]) (4.55.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->unstructured-inference==0.8.1->unstructured[pdf]) (1.4.7)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->unstructured-inference==0.8.1->unstructured[pdf]) (3.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<2.10.0,>=2.9.2->unstructured-client->unstructured[pdf]) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<2.10.0,>=2.9.2->unstructured-client->unstructured[pdf]) (2.23.4)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from timm->unstructured-inference==0.8.1->unstructured[pdf]) (0.4.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->unstructured-inference==0.8.1->unstructured[pdf]) (3.16.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->unstructured-inference==0.8.1->unstructured[pdf]) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->unstructured-inference==0.8.1->unstructured[pdf]) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->unstructured-inference==0.8.1->unstructured[pdf]) (2024.10.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime>=1.17.0->unstructured-inference==0.8.1->unstructured[pdf]) (1.3.0)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.25.1->unstructured-inference==0.8.1->unstructured[pdf]) (0.20.3)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json->unstructured[pdf]) (1.0.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from layoutparser->unstructured-inference==0.8.1->unstructured[pdf]) (1.13.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from layoutparser->unstructured-inference==0.8.1->unstructured[pdf]) (2.2.2)\n",
            "Collecting iopath (from layoutparser->unstructured-inference==0.8.1->unstructured[pdf])\n",
            "  Downloading iopath-0.1.10.tar.gz (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pdfplumber (from layoutparser->unstructured-inference==0.8.1->unstructured[pdf])\n",
            "  Downloading pdfplumber-0.11.4-py3-none-any.whl.metadata (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.0/42.0 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six->unstructured[pdf]) (2.22)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-vision->unstructured[pdf]) (0.6.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.27.0->unstructured-client->unstructured[pdf]) (1.2.2)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.17.0->unstructured-inference==0.8.1->unstructured[pdf])\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Collecting portalocker (from iopath->layoutparser->unstructured-inference==0.8.1->unstructured[pdf])\n",
            "  Downloading portalocker-3.0.0-py3-none-any.whl.metadata (8.5 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->unstructured-inference==0.8.1->unstructured[pdf]) (3.0.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->layoutparser->unstructured-inference==0.8.1->unstructured[pdf]) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->layoutparser->unstructured-inference==0.8.1->unstructured[pdf]) (2024.2)\n",
            "Collecting pdfminer.six (from unstructured[pdf])\n",
            "  Downloading pdfminer.six-20231228-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting pypdfium2>=4.18.0 (from pdfplumber->layoutparser->unstructured-inference==0.8.1->unstructured[pdf])\n",
            "  Downloading pypdfium2-4.30.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (48 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.5/48.5 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading unstructured_inference-0.8.1-py3-none-any.whl (48 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.4/48.4 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading unstructured.pytesseract-0.3.13-py3-none-any.whl (14 kB)\n",
            "Downloading effdet-0.4.1-py3-none-any.whl (112 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.5/112.5 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading google_cloud_vision-3.8.1-py2.py3-none-any.whl (486 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m486.9/486.9 kB\u001b[0m \u001b[31m29.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnx-1.17.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.0/16.0 MB\u001b[0m \u001b[31m75.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pdf2image-1.17.0-py3-none-any.whl (11 kB)\n",
            "Downloading pi_heif-0.20.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (989 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m989.0/989.0 kB\u001b[0m \u001b[31m46.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pikepdf-9.4.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m65.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxruntime-1.20.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (13.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m52.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading layoutparser-0.3.4-py3-none-any.whl (19.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.2/19.2 MB\u001b[0m \u001b[31m50.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_multipart-0.0.17-py3-none-any.whl (24 kB)\n",
            "Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pdfplumber-0.11.4-py3-none-any.whl (59 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.2/59.2 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pdfminer.six-20231228-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m93.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pypdfium2-4.30.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m55.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading portalocker-3.0.0-py3-none-any.whl (19 kB)\n",
            "Building wheels for collected packages: antlr4-python3-runtime, iopath\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144555 sha256=e966b95a6d8f985df5a974d19f1c56588184a3d26ed36f0cdab5478e4734fa62\n",
            "  Stored in directory: /root/.cache/pip/wheels/12/93/dd/1f6a127edc45659556564c5730f6d4e300888f4bca2d4c5a88\n",
            "  Building wheel for iopath (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for iopath: filename=iopath-0.1.10-py3-none-any.whl size=31528 sha256=7f8d6bab58b16758c6c2078f04aaf47b3d48f71c3b439f2af8ea5fb151bad5c2\n",
            "  Stored in directory: /root/.cache/pip/wheels/9a/a3/b6/ac0fcd1b4ed5cfeb3db92e6a0e476cfd48ed0df92b91080c1d\n",
            "Successfully built antlr4-python3-runtime iopath\n",
            "Installing collected packages: antlr4-python3-runtime, unstructured.pytesseract, python-multipart, pypdfium2, portalocker, pi-heif, pdf2image, onnx, omegaconf, humanfriendly, pikepdf, iopath, coloredlogs, pdfminer.six, onnxruntime, pdfplumber, layoutparser, google-cloud-vision, effdet, unstructured-inference\n",
            "Successfully installed antlr4-python3-runtime-4.9.3 coloredlogs-15.0.1 effdet-0.4.1 google-cloud-vision-3.8.1 humanfriendly-10.0 iopath-0.1.10 layoutparser-0.3.4 omegaconf-2.3.0 onnx-1.17.0 onnxruntime-1.20.1 pdf2image-1.17.0 pdfminer.six-20231228 pdfplumber-0.11.4 pi-heif-0.20.0 pikepdf-9.4.2 portalocker-3.0.0 pypdfium2-4.30.0 python-multipart-0.0.17 unstructured-inference-0.8.1 unstructured.pytesseract-0.3.13\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google",
                  "pydevd_plugins"
                ]
              },
              "id": "2724f0760057465ab4269ec00b12545c"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install unstructured\n",
        "!pip install \"unstructured[pdf]\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "noStRcDmCweN",
        "outputId": "0780dcf3-fc0a-4929-d88e-7badb4bccde5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        }
      ],
      "source": [
        "from langchain.document_loaders import DirectoryLoader\n",
        "\n",
        "loader = DirectoryLoader(\"./data\",glob = \"**/*.pdf\")\n",
        "data = loader.load()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZrWdn1M0EdxX",
        "outputId": "693252cb-6b83-4ab0-ee09-1eea9cea2f57"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Document(page_content='You Only Look Once (YOLO): Unified, Real-Time Object Detection\\n\\nPresenter: Shivang Singh\\n\\nSept 2nd, 2021\\n\\nCS391R: Robot Learning (Fall 2021)\\n\\n1\\n\\nProblem Addressed: Object Detection\\n\\n❖ Object detection is the problem of both\\n\\nlocating AND classifying objects\\n\\n❖ Goal of YOLO algorithm is to do object\\n\\ndetection both fast AND with high\\n\\naccuracy\\n\\n“Deep Learning for Vision Systems” (Elgendy)\\n\\nCS391R: Robot Learning (Fall 2021)\\n\\nObject Detection vs Classification\\n\\n2\\n\\nImportance of Object Detection for Robotics\\n\\n❖ Visual modality is very powerful\\n\\n❖ Humans are able to detect objects and do\\n\\nVision based vs LIDAR (self driving)\\n\\nperception using just this modality in real time\\n\\n(not needing radar)\\n\\n❖ If we want responsive robot systems that\\n\\nwork in real time (without specialized\\n\\nsensors) almost real time vision based object\\n\\ndetection can help greatly\\n\\nTesla Investor Day Presentation\\n\\nCS391R: Robot Learning (Fall 2021)\\n\\n3\\n\\nPrevious Object Detection Paradigm This pipeline was used in nearly all SOTA Object Detection prior:\\n\\nLabel + confidence\\n\\nImage Classifier\\n\\nhat - 0.92 racket - 0.2 ball - 0.23\\n\\nStep 1: Scan the image to generate candidate bounding boxes\\n\\nStep 2: Run the bounding box through a classifier\\n\\nStep 3: Conduct post-processing (filtering out redundant bounding boxes)\\n\\nDiagram developed by presenter\\n\\nCS391R: Robot Learning (Fall 2021)\\n\\n4\\n\\nKey Insights\\n\\nPrevious Approaches\\n\\n❖ A separate model for generating\\n\\nbounding boxes and for classification\\n\\n(more complicated model pipeline)\\n\\n❖ Need to run classification many\\n\\ntimes (expensive computation)\\n\\n❖ Looks at limited part of the image\\n\\n(lacks contextual information for\\n\\ndetection)\\n\\nCS391R: Robot Learning (Fall 2021)\\n\\nYOLO algorithm\\n\\n❖ A single neural network for\\n\\nlocalization and for classification\\n\\n(less complicated pipeline)\\n\\n❖ Need to inference only once\\n\\n(efficient computation)\\n\\n❖ Looks at the entire image each time\\n\\nleading to less false positives (has\\n\\ncontextual information for detection)\\n\\n5\\n\\nFormal Problem Setting\\n\\n❖ Given an image generate bounding boxes, one for\\n\\neach detectable object in image\\n\\n❖ For each bounding box, output 5 predictions: x, y, w,\\n\\nh, confidence. Also output class\\n\\n❖ x, y (coordinates for center of bounding box)\\n\\n❖ w,h (width and height)\\n\\n❖ confidence (probability bounding box has object)\\n\\n❖ class (classification of object in bounding box)\\n\\nCS391R: Robot Learning (Fall 2021)\\n\\n6\\n\\nRelated Work\\n\\nR-CNN or Region Based Convolutional Network (Girshick et al. 2014):\\n\\n\\n\\n-\\n\\nUsed the sliding window approach from earlier, with Selective Search, a smarter way to select candidates (which means there is less computation) Still feeds a limited part of the image to the classifier Drawbacks: Large pipeline, slow, too many false positives\\n\\nFast and Faster R-CNN:\\n\\nOptimize parts of the pipeline described earlier - Drawbacks: loses accuracy\\n\\nDeep Multibox (Szegedy et. al 2014):\\n\\n-\\n\\nTrain a CNN to find areas of interest Drawbacks: Doesn’t address classification only localization\\n\\nCS391R: Robot Learning (Fall 2021)\\n\\n7\\n\\nRelated Work\\n\\nMultiGrasp (Redmon et. al 2014)\\n\\nSimilar to YOLO - A much simpler task (only needs to predict object not multiple objects)\\n\\nCS391R: Robot Learning (Fall 2021)\\n\\n8\\n\\nYOLO overview\\n\\n❖ First, image is split into a SxS grid ❖ For each grid square, generate B bounding boxes ❖ For each bounding box, there are 5 predictions: x, y, w, h,\\n\\nconfidence\\n\\nCS391R: Robot Learning (Fall 2021)\\n\\nS = 3, B = 2\\n\\n9\\n\\nYOLO Training\\n\\n❖ YOLO is a regression algorithm. What is\\n\\nX? What is Y?\\n\\n❖ X is simple, just an image width (in\\n\\npixels) * height (in pixels) * RGB values ❖ Y is a tensor of size S * S * (B * 5 + C) ❖ B*5 + C term represents the predictions\\n\\n+ class predicted distribution for a grid\\n\\nblock\\n\\nCS391R: Robot Learning (Fall 2021)\\n\\nFor each grid block, we have a\\n\\nvector like this. For this example\\n\\nB is 2 and C is 2\\n\\nGT label\\n\\nexample:\\n\\n10\\n\\nYOLO Architecture\\n\\nNow that we know the input and output, we can discuss the model\\n\\nWe are given 448 by 448 by 3 as\\n\\n\\n\\nour input. Implementation uses 7 convolution layers\\n\\nPaper parameters: S = 7, B = 2,\\n\\nC = 20\\n\\nOutput is S*S*(5B+C) = 7*7*(5*2+20) = 7*7*30\\n\\nCS391R: Robot Learning (Fall 2021)\\n\\n11\\n\\nYOLO Prediction\\n\\n❖ We then use the output to make final detections ❖ Use a threshold to filter out bounding boxes with\\n\\nlow P(Object)\\n\\n❖ In order to know the class for the bounding box\\n\\ncompute score take argmax over the distribution\\n\\nPr(Class|Object) for the grid the bounding box’s\\n\\ncenter is in\\n\\nCS391R: Robot Learning (Fall 2021)\\n\\n12\\n\\nNon-maximal suppression\\n\\n❖ Most of the time objects fall in one grid,\\n\\nhowever it is still possible to get redundant boxes (rare case as object must be close to multiple grid cells for this to happen) ❖ Discard bounding box with high overlap (keeping the bounding box with highest confidence)\\n\\n❖ Adds 2-3% on final mAP score\\n\\nCS391R: Robot Learning (Fall 2021)\\n\\n13\\n\\nYOLO Objective Function\\n\\n❖ For YOLO, we need to minimize the following loss ❖ Sum squared error is used\\n\\nCoordinate Loss: Minimize the difference between x,y,w,h pred and x,y,w,h ground truth. ONLY IF object exists in grid box and if bounding box is resp for pred\\n\\nConfidence Loss: Loss based on confidence ONLY IF there is object\\n\\nNo Object Loss based on confidence if there is no object\\n\\nClass loss, minimize loss between true class of object in grid box\\n\\nCS391R: Robot Learning (Fall 2021)\\n\\n14\\n\\nExperimental Setup\\n\\n❖ Authors compare YOLO against the previous work described above on PASCAL VOC 2007, and\\n\\nVOC 2012 as well as out of domain art dataset\\n\\n❖ Correct if IOU metric above .5 and class is correct\\n\\n❖ Use two performance metrics:\\n\\n➢ mAP score: mean average precision\\n\\n➢ FPS:\\n\\nframes per second\\n\\n❖ Add FAST YOLO: which has less parameters\\n\\nCS391R: Robot Learning (Fall 2021)\\n\\n15\\n\\nExperimental Results\\n\\n❖ Baseline YOLO outperform\\n\\nreal time detectors by large\\n\\namount\\n\\n❖ Do better than most less than\\n\\nreal time as well\\n\\nCS391R: Robot Learning (Fall 2021)\\n\\n16\\n\\nExperimental Results\\n\\nCS391R: Robot Learning (Fall 2021)\\n\\n17\\n\\nExperimental Results - Error Analysis Exper\\n\\nMakes far less background errors (less likely to predict false positives on background) IOU is VERY small with any ground truth label\\n\\n\\n\\nBut far more localization errors\\n\\n\\n\\nCorrect class, IOU is somewhat small\\n\\nLocalization error\\n\\nCS391R: Robot Learning (Fall 2021)\\n\\nBackground error\\n\\n18\\n\\nExperimental Results - Out of Domain\\n\\n❖ Ran YOLO + competitors\\n\\n(trained on natural images) on art\\n\\n❖ Does well on artistic datasets where more having global context greatly helps\\n\\nCS391R: Robot Learning (Fall 2021)\\n\\n19\\n\\nDiscussion of Results\\n\\n❖ Pro: YOLO is a lot faster than the other algorithms for image detection\\n\\n❖ Pro: YOLO’s use of global information rather than only local information allows it to understand\\n\\ncontextual information when doing object detection\\n\\n➢ Does better in domains such as artwork due to this\\n\\n❖ Con: YOLO lagged behind the SOTA models in object detection\\n\\n➢ This is attributed to making many localization errors and unable to detect small object\\n\\nCS391R: Robot Learning (Fall 2021)\\n\\n20\\n\\nCritique / Limitations / Open Issues\\n\\n❖ Performance lags behind SOTA\\n\\n❖ Requires data to be labeled with bounding boxes, hard to collect for many classes\\n\\n➢ Previous work could generalize better since it used image classifier\\n\\n➢ 2014 COCO dataset (very large dataset) addressed this somewhat\\n\\n❖ Regarding experiments: number of classes predicted is very limited\\n\\n➢ Not convinced that YOLO v1 is generalizable\\n\\n❖ Confidence output of YOLO not confidence of class but P(Object), lowers interpretability\\n\\n❖ Another limitation of YOLO is that it imposed spatial constraints on the objects in the image since\\n\\nonly B boxes can be predicted on an SxS grid\\n\\n❖ Since the architecture only predicts boxes, this might make it less useful for irregular shapes\\n\\nCS391R: Robot Learning (Fall 2021)\\n\\n21\\n\\nFuture Work for Paper / Reading\\n\\n❖ One extension of this work would be to look\\n\\nat image segmentation and see if the insights\\n\\ncarry over\\n\\nYOLOACT (Boyla et al 2019): Real\\n\\ntime image segmentation ❖ YOLO has been upgraded 2 times\\n\\nSolves a lot of issues relating to\\n\\ndetecting small objects,\\n\\ngeneralizability, and localization\\n\\nCS391R: Robot Learning (Fall 2021)\\n\\nYOLOACT example\\n\\n22\\n\\nExtended Readings\\n\\n❖ YOLO v2 (https://arxiv.org/abs/1506.02640) (extends on the work greatly) (Redmond et al 2016)\\n\\n➢ Deals with the generalizability problem, has 9000 classes\\n\\n➢ Class probability distribution per bounding box, not per grid\\n\\n➢ High resolution classifier (finetune on high resolution)\\n\\n➢ Batch norm\\n\\n➢ Trained on MSCOCO (released after YOLO v1 paper)\\n\\n❖ YOLO v3 (https://arxiv.org/abs/1804.02767)\\n\\n➢ “Incremental Improvement”\\n\\n➢ Uses independent logistic classifiers for class\\n\\n■ Allows for more specificity in classes\\n\\nCS391R: Robot Learning (Fall 2021)\\n\\n23\\n\\nSummary\\n\\n❖ Object detection is the problem of detecting multiple objects in an image ❖ Almost real time object detection can make highly responsive robot systems without complex sensors ❖ Prior work relies on a large architecture with numerous parts to optimize ❖ YOLO proposes a unified architecture, which does all the tasks in one model and by one inference\\n\\nover the entire image\\n\\n❖ They show enormous speed improvement and show that they can beat most other prior work in terms\\n\\nof mAPs\\n\\nCS391R: Robot Learning (Fall 2021)\\n\\n24', metadata={'source': 'data/yolo.pdf'})]"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ig_Tc37GEhV_"
      },
      "source": [
        "## Text Splitting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v28l9Y3lEdvH"
      },
      "outputs": [],
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=20)\n",
        "docs = text_splitter.split_documents(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NVSqLB3GEds-",
        "outputId": "fe49a831-e04c-4795-93e9-f1e9de81f538"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Document(page_content='You Only Look Once (YOLO): Unified, Real-Time Object Detection\\n\\nPresenter: Shivang Singh\\n\\nSept 2nd, 2021\\n\\nCS391R: Robot Learning (Fall 2021)\\n\\n1\\n\\nProblem Addressed: Object Detection\\n\\n❖ Object detection is the problem of both\\n\\nlocating AND classifying objects\\n\\n❖ Goal of YOLO algorithm is to do object\\n\\ndetection both fast AND with high\\n\\naccuracy\\n\\n“Deep Learning for Vision Systems” (Elgendy)\\n\\nCS391R: Robot Learning (Fall 2021)\\n\\nObject Detection vs Classification\\n\\n2\\n\\nImportance of Object Detection for Robotics\\n\\n❖ Visual modality is very powerful\\n\\n❖ Humans are able to detect objects and do\\n\\nVision based vs LIDAR (self driving)\\n\\nperception using just this modality in real time\\n\\n(not needing radar)\\n\\n❖ If we want responsive robot systems that\\n\\nwork in real time (without specialized\\n\\nsensors) almost real time vision based object\\n\\ndetection can help greatly\\n\\nTesla Investor Day Presentation\\n\\nCS391R: Robot Learning (Fall 2021)\\n\\n3', metadata={'source': 'data/yolo.pdf'}),\n",
              " Document(page_content='3\\n\\nPrevious Object Detection Paradigm This pipeline was used in nearly all SOTA Object Detection prior:\\n\\nLabel + confidence\\n\\nImage Classifier\\n\\nhat - 0.92 racket - 0.2 ball - 0.23\\n\\nStep 1: Scan the image to generate candidate bounding boxes\\n\\nStep 2: Run the bounding box through a classifier\\n\\nStep 3: Conduct post-processing (filtering out redundant bounding boxes)\\n\\nDiagram developed by presenter\\n\\nCS391R: Robot Learning (Fall 2021)\\n\\n4\\n\\nKey Insights\\n\\nPrevious Approaches\\n\\n❖ A separate model for generating\\n\\nbounding boxes and for classification\\n\\n(more complicated model pipeline)\\n\\n❖ Need to run classification many\\n\\ntimes (expensive computation)\\n\\n❖ Looks at limited part of the image\\n\\n(lacks contextual information for\\n\\ndetection)\\n\\nCS391R: Robot Learning (Fall 2021)\\n\\nYOLO algorithm\\n\\n❖ A single neural network for\\n\\nlocalization and for classification\\n\\n(less complicated pipeline)\\n\\n❖ Need to inference only once\\n\\n(efficient computation)\\n\\n❖ Looks at the entire image each time', metadata={'source': 'data/yolo.pdf'}),\n",
              " Document(page_content='leading to less false positives (has\\n\\ncontextual information for detection)\\n\\n5\\n\\nFormal Problem Setting\\n\\n❖ Given an image generate bounding boxes, one for\\n\\neach detectable object in image\\n\\n❖ For each bounding box, output 5 predictions: x, y, w,\\n\\nh, confidence. Also output class\\n\\n❖ x, y (coordinates for center of bounding box)\\n\\n❖ w,h (width and height)\\n\\n❖ confidence (probability bounding box has object)\\n\\n❖ class (classification of object in bounding box)\\n\\nCS391R: Robot Learning (Fall 2021)\\n\\n6\\n\\nRelated Work\\n\\nR-CNN or Region Based Convolutional Network (Girshick et al. 2014):\\n\\n\\n\\n-\\n\\nUsed the sliding window approach from earlier, with Selective Search, a smarter way to select candidates (which means there is less computation) Still feeds a limited part of the image to the classifier Drawbacks: Large pipeline, slow, too many false positives\\n\\nFast and Faster R-CNN:\\n\\nOptimize parts of the pipeline described earlier - Drawbacks: loses accuracy\\n\\nDeep Multibox (Szegedy et. al 2014):\\n\\n-', metadata={'source': 'data/yolo.pdf'}),\n",
              " Document(page_content='-\\n\\nTrain a CNN to find areas of interest Drawbacks: Doesn’t address classification only localization\\n\\nCS391R: Robot Learning (Fall 2021)\\n\\n7\\n\\nRelated Work\\n\\nMultiGrasp (Redmon et. al 2014)\\n\\nSimilar to YOLO - A much simpler task (only needs to predict object not multiple objects)\\n\\nCS391R: Robot Learning (Fall 2021)\\n\\n8\\n\\nYOLO overview\\n\\n❖ First, image is split into a SxS grid ❖ For each grid square, generate B bounding boxes ❖ For each bounding box, there are 5 predictions: x, y, w, h,\\n\\nconfidence\\n\\nCS391R: Robot Learning (Fall 2021)\\n\\nS = 3, B = 2\\n\\n9\\n\\nYOLO Training\\n\\n❖ YOLO is a regression algorithm. What is\\n\\nX? What is Y?\\n\\n❖ X is simple, just an image width (in\\n\\npixels) * height (in pixels) * RGB values ❖ Y is a tensor of size S * S * (B * 5 + C) ❖ B*5 + C term represents the predictions\\n\\n+ class predicted distribution for a grid\\n\\nblock\\n\\nCS391R: Robot Learning (Fall 2021)\\n\\nFor each grid block, we have a\\n\\nvector like this. For this example\\n\\nB is 2 and C is 2\\n\\nGT label\\n\\nexample:\\n\\n10', metadata={'source': 'data/yolo.pdf'}),\n",
              " Document(page_content='example:\\n\\n10\\n\\nYOLO Architecture\\n\\nNow that we know the input and output, we can discuss the model\\n\\nWe are given 448 by 448 by 3 as\\n\\n\\n\\nour input. Implementation uses 7 convolution layers\\n\\nPaper parameters: S = 7, B = 2,\\n\\nC = 20\\n\\nOutput is S*S*(5B+C) = 7*7*(5*2+20) = 7*7*30\\n\\nCS391R: Robot Learning (Fall 2021)\\n\\n11\\n\\nYOLO Prediction\\n\\n❖ We then use the output to make final detections ❖ Use a threshold to filter out bounding boxes with\\n\\nlow P(Object)\\n\\n❖ In order to know the class for the bounding box\\n\\ncompute score take argmax over the distribution\\n\\nPr(Class|Object) for the grid the bounding box’s\\n\\ncenter is in\\n\\nCS391R: Robot Learning (Fall 2021)\\n\\n12\\n\\nNon-maximal suppression\\n\\n❖ Most of the time objects fall in one grid,\\n\\nhowever it is still possible to get redundant boxes (rare case as object must be close to multiple grid cells for this to happen) ❖ Discard bounding box with high overlap (keeping the bounding box with highest confidence)\\n\\n❖ Adds 2-3% on final mAP score', metadata={'source': 'data/yolo.pdf'}),\n",
              " Document(page_content='CS391R: Robot Learning (Fall 2021)\\n\\n13\\n\\nYOLO Objective Function\\n\\n❖ For YOLO, we need to minimize the following loss ❖ Sum squared error is used\\n\\nCoordinate Loss: Minimize the difference between x,y,w,h pred and x,y,w,h ground truth. ONLY IF object exists in grid box and if bounding box is resp for pred\\n\\nConfidence Loss: Loss based on confidence ONLY IF there is object\\n\\nNo Object Loss based on confidence if there is no object\\n\\nClass loss, minimize loss between true class of object in grid box\\n\\nCS391R: Robot Learning (Fall 2021)\\n\\n14\\n\\nExperimental Setup\\n\\n❖ Authors compare YOLO against the previous work described above on PASCAL VOC 2007, and\\n\\nVOC 2012 as well as out of domain art dataset\\n\\n❖ Correct if IOU metric above .5 and class is correct\\n\\n❖ Use two performance metrics:\\n\\n➢ mAP score: mean average precision\\n\\n➢ FPS:\\n\\nframes per second\\n\\n❖ Add FAST YOLO: which has less parameters\\n\\nCS391R: Robot Learning (Fall 2021)\\n\\n15\\n\\nExperimental Results\\n\\n❖ Baseline YOLO outperform', metadata={'source': 'data/yolo.pdf'}),\n",
              " Document(page_content='real time detectors by large\\n\\namount\\n\\n❖ Do better than most less than\\n\\nreal time as well\\n\\nCS391R: Robot Learning (Fall 2021)\\n\\n16\\n\\nExperimental Results\\n\\nCS391R: Robot Learning (Fall 2021)\\n\\n17\\n\\nExperimental Results - Error Analysis Exper\\n\\nMakes far less background errors (less likely to predict false positives on background) IOU is VERY small with any ground truth label\\n\\n\\n\\nBut far more localization errors\\n\\n\\n\\nCorrect class, IOU is somewhat small\\n\\nLocalization error\\n\\nCS391R: Robot Learning (Fall 2021)\\n\\nBackground error\\n\\n18\\n\\nExperimental Results - Out of Domain\\n\\n❖ Ran YOLO + competitors\\n\\n(trained on natural images) on art\\n\\n❖ Does well on artistic datasets where more having global context greatly helps\\n\\nCS391R: Robot Learning (Fall 2021)\\n\\n19\\n\\nDiscussion of Results\\n\\n❖ Pro: YOLO is a lot faster than the other algorithms for image detection\\n\\n❖ Pro: YOLO’s use of global information rather than only local information allows it to understand\\n\\ncontextual information when doing object detection', metadata={'source': 'data/yolo.pdf'}),\n",
              " Document(page_content='➢ Does better in domains such as artwork due to this\\n\\n❖ Con: YOLO lagged behind the SOTA models in object detection\\n\\n➢ This is attributed to making many localization errors and unable to detect small object\\n\\nCS391R: Robot Learning (Fall 2021)\\n\\n20\\n\\nCritique / Limitations / Open Issues\\n\\n❖ Performance lags behind SOTA\\n\\n❖ Requires data to be labeled with bounding boxes, hard to collect for many classes\\n\\n➢ Previous work could generalize better since it used image classifier\\n\\n➢ 2014 COCO dataset (very large dataset) addressed this somewhat\\n\\n❖ Regarding experiments: number of classes predicted is very limited\\n\\n➢ Not convinced that YOLO v1 is generalizable\\n\\n❖ Confidence output of YOLO not confidence of class but P(Object), lowers interpretability\\n\\n❖ Another limitation of YOLO is that it imposed spatial constraints on the objects in the image since\\n\\nonly B boxes can be predicted on an SxS grid\\n\\n❖ Since the architecture only predicts boxes, this might make it less useful for irregular shapes', metadata={'source': 'data/yolo.pdf'}),\n",
              " Document(page_content='CS391R: Robot Learning (Fall 2021)\\n\\n21\\n\\nFuture Work for Paper / Reading\\n\\n❖ One extension of this work would be to look\\n\\nat image segmentation and see if the insights\\n\\ncarry over\\n\\nYOLOACT (Boyla et al 2019): Real\\n\\ntime image segmentation ❖ YOLO has been upgraded 2 times\\n\\nSolves a lot of issues relating to\\n\\ndetecting small objects,\\n\\ngeneralizability, and localization\\n\\nCS391R: Robot Learning (Fall 2021)\\n\\nYOLOACT example\\n\\n22\\n\\nExtended Readings\\n\\n❖ YOLO v2 (https://arxiv.org/abs/1506.02640) (extends on the work greatly) (Redmond et al 2016)\\n\\n➢ Deals with the generalizability problem, has 9000 classes\\n\\n➢ Class probability distribution per bounding box, not per grid\\n\\n➢ High resolution classifier (finetune on high resolution)\\n\\n➢ Batch norm\\n\\n➢ Trained on MSCOCO (released after YOLO v1 paper)\\n\\n❖ YOLO v3 (https://arxiv.org/abs/1804.02767)\\n\\n➢ “Incremental Improvement”\\n\\n➢ Uses independent logistic classifiers for class\\n\\n■ Allows for more specificity in classes\\n\\nCS391R: Robot Learning (Fall 2021)', metadata={'source': 'data/yolo.pdf'}),\n",
              " Document(page_content='23\\n\\nSummary\\n\\n❖ Object detection is the problem of detecting multiple objects in an image ❖ Almost real time object detection can make highly responsive robot systems without complex sensors ❖ Prior work relies on a large architecture with numerous parts to optimize ❖ YOLO proposes a unified architecture, which does all the tasks in one model and by one inference\\n\\nover the entire image\\n\\n❖ They show enormous speed improvement and show that they can beat most other prior work in terms\\n\\nof mAPs\\n\\nCS391R: Robot Learning (Fall 2021)\\n\\n24', metadata={'source': 'data/yolo.pdf'})]"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "docs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H0du36H1EmR9",
        "outputId": "cd0c25ab-6a58-49c2-ceef-8c944021581c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(docs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KAWoYPCCEr-P"
      },
      "source": [
        "## Embedding Convertion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U13DhBHdEoLf"
      },
      "outputs": [],
      "source": [
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "\n",
        "embeddings = OpenAIEmbeddings(openai_api_key= OPENAI_API_KEY)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3t7wpOMwF93g",
        "outputId": "3fb54c60-4bbb-4f51-c35e-506e30d1c139"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "OpenAIEmbeddings(client=<class 'openai.api_resources.embedding.Embedding'>, model='text-embedding-ada-002', deployment='text-embedding-ada-002', openai_api_version='', openai_api_base='', openai_api_type='', openai_proxy='', embedding_ctx_length=8191, openai_api_key='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', openai_organization='', allowed_special=set(), disallowed_special='all', chunk_size=1000, max_retries=6, request_timeout=None, headers=None, tiktoken_model_name=None, show_progress_bar=False, model_kwargs={}, skip_empty=False)"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pa6pqWXVE5b2"
      },
      "source": [
        "## Vector Database Storage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gu-4tnGSE3H2"
      },
      "outputs": [],
      "source": [
        "import weaviate\n",
        "from langchain.vectorstores import Weaviate\n",
        "\n",
        "#Connect to weaviate Cluster\n",
        "auth_config = weaviate.auth.AuthApiKey(api_key = WEAVIATE_API_KEY)\n",
        "WEAVIATE_URL = WEAVIATE_CLUSTER\n",
        "\n",
        "client = weaviate.Client(\n",
        "    url = WEAVIATE_URL,\n",
        "    additional_headers = {\" \": OPENAI_API_KEY},\n",
        "    auth_client_secret = auth_config,\n",
        "    startup_period = 10\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zLrjVzwkE3Fv",
        "outputId": "65908f1e-1345-4ecf-e2fb-55209c94069d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "client.is_ready()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-8pusC7QFWUf"
      },
      "outputs": [],
      "source": [
        "# define input structure\n",
        "client.schema.delete_all()\n",
        "client.schema.get()\n",
        "schema = {\n",
        "    \"classes\": [\n",
        "        {\n",
        "            \"class\": \"Chatbot\",\n",
        "            \"description\": \"Documents for chatbot\",\n",
        "            \"vectorizer\": \"text2vec-openai\",\n",
        "            \"moduleConfig\": {\"text2vec-openai\": {\"model\": \"ada\", \"type\": \"text\"}},\n",
        "            \"properties\": [\n",
        "                {\n",
        "                    \"dataType\": [\"text\"],\n",
        "                    \"description\": \"The content of the paragraph\",\n",
        "                    \"moduleConfig\": {\n",
        "                        \"text2vec-openai\": {\n",
        "                            \"skip\": False,\n",
        "                            \"vectorizePropertyName\": False,\n",
        "                        }\n",
        "                    },\n",
        "                    \"name\": \"content\",\n",
        "                },\n",
        "            ],\n",
        "        },\n",
        "    ]\n",
        "}\n",
        "\n",
        "client.schema.create(schema)\n",
        "vectorstore = Weaviate(client, \"Chatbot\", \"content\", attributes=[\"source\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mAAP1K88GDXW",
        "outputId": "d4f0eb14-740d-4f05-8080-dc391269cb81"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['9c496404-7515-4b3c-8b8e-88e2dc09dfc8',\n",
              " '0c6883df-8242-4011-a51d-13efd4d6dd39',\n",
              " '3ad7f0e4-d5b9-4ffc-9fb0-1d4a4b31f610',\n",
              " '4845d89b-4e65-4ec3-ac46-e182793e9b68',\n",
              " '32df9a02-fdf1-4e71-81b5-1103264f7499',\n",
              " '6e2be198-6bb7-4374-8bf8-bc3f42aefd17',\n",
              " '5074cbc0-870c-416e-a37c-63a8f28a06bd',\n",
              " '59fd3d13-29f3-4001-af59-7fc48a4e1bec',\n",
              " 'cb52baa4-bd78-4491-801e-21b074f6aa8d',\n",
              " '631ccd1a-e35d-4eb4-94ae-8beb3c1f99e4']"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# load text into the vectorstore\n",
        "text_meta_pair = [(doc.page_content, doc.metadata) for doc in docs]\n",
        "texts, meta = list(zip(*text_meta_pair))\n",
        "vectorstore.add_texts(texts, meta)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qMNy5RQ9Gjn1"
      },
      "source": [
        "## Similarity Measurement"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BNFmkvRsGDVI"
      },
      "outputs": [],
      "source": [
        "query = \"what is a yolo?\"\n",
        "\n",
        "# retrieve text related to the query\n",
        "docs = vectorstore.similarity_search(query, top_k=20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KJ8RTLX0GrFe",
        "outputId": "c21e2a31-6143-466e-9ef6-98e3f6600c9f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Document(page_content='You Only Look Once (YOLO): Unified, Real-Time Object Detection\\n\\nPresenter: Shivang Singh\\n\\nSept 2nd, 2021\\n\\nCS391R: Robot Learning (Fall 2021)\\n\\n1\\n\\nProblem Addressed: Object Detection\\n\\n❖ Object detection is the problem of both\\n\\nlocating AND classifying objects\\n\\n❖ Goal of YOLO algorithm is to do object\\n\\ndetection both fast AND with high\\n\\naccuracy\\n\\n“Deep Learning for Vision Systems” (Elgendy)\\n\\nCS391R: Robot Learning (Fall 2021)\\n\\nObject Detection vs Classification\\n\\n2\\n\\nImportance of Object Detection for Robotics\\n\\n❖ Visual modality is very powerful\\n\\n❖ Humans are able to detect objects and do\\n\\nVision based vs LIDAR (self driving)\\n\\nperception using just this modality in real time\\n\\n(not needing radar)\\n\\n❖ If we want responsive robot systems that\\n\\nwork in real time (without specialized\\n\\nsensors) almost real time vision based object\\n\\ndetection can help greatly\\n\\nTesla Investor Day Presentation\\n\\nCS391R: Robot Learning (Fall 2021)\\n\\n3', metadata={'source': 'data/yolo.pdf'}),\n",
              " Document(page_content='23\\n\\nSummary\\n\\n❖ Object detection is the problem of detecting multiple objects in an image ❖ Almost real time object detection can make highly responsive robot systems without complex sensors ❖ Prior work relies on a large architecture with numerous parts to optimize ❖ YOLO proposes a unified architecture, which does all the tasks in one model and by one inference\\n\\nover the entire image\\n\\n❖ They show enormous speed improvement and show that they can beat most other prior work in terms\\n\\nof mAPs\\n\\nCS391R: Robot Learning (Fall 2021)\\n\\n24', metadata={'source': 'data/yolo.pdf'}),\n",
              " Document(page_content='CS391R: Robot Learning (Fall 2021)\\n\\n13\\n\\nYOLO Objective Function\\n\\n❖ For YOLO, we need to minimize the following loss ❖ Sum squared error is used\\n\\nCoordinate Loss: Minimize the difference between x,y,w,h pred and x,y,w,h ground truth. ONLY IF object exists in grid box and if bounding box is resp for pred\\n\\nConfidence Loss: Loss based on confidence ONLY IF there is object\\n\\nNo Object Loss based on confidence if there is no object\\n\\nClass loss, minimize loss between true class of object in grid box\\n\\nCS391R: Robot Learning (Fall 2021)\\n\\n14\\n\\nExperimental Setup\\n\\n❖ Authors compare YOLO against the previous work described above on PASCAL VOC 2007, and\\n\\nVOC 2012 as well as out of domain art dataset\\n\\n❖ Correct if IOU metric above .5 and class is correct\\n\\n❖ Use two performance metrics:\\n\\n➢ mAP score: mean average precision\\n\\n➢ FPS:\\n\\nframes per second\\n\\n❖ Add FAST YOLO: which has less parameters\\n\\nCS391R: Robot Learning (Fall 2021)\\n\\n15\\n\\nExperimental Results\\n\\n❖ Baseline YOLO outperform', metadata={'source': 'data/yolo.pdf'}),\n",
              " Document(page_content='➢ Does better in domains such as artwork due to this\\n\\n❖ Con: YOLO lagged behind the SOTA models in object detection\\n\\n➢ This is attributed to making many localization errors and unable to detect small object\\n\\nCS391R: Robot Learning (Fall 2021)\\n\\n20\\n\\nCritique / Limitations / Open Issues\\n\\n❖ Performance lags behind SOTA\\n\\n❖ Requires data to be labeled with bounding boxes, hard to collect for many classes\\n\\n➢ Previous work could generalize better since it used image classifier\\n\\n➢ 2014 COCO dataset (very large dataset) addressed this somewhat\\n\\n❖ Regarding experiments: number of classes predicted is very limited\\n\\n➢ Not convinced that YOLO v1 is generalizable\\n\\n❖ Confidence output of YOLO not confidence of class but P(Object), lowers interpretability\\n\\n❖ Another limitation of YOLO is that it imposed spatial constraints on the objects in the image since\\n\\nonly B boxes can be predicted on an SxS grid\\n\\n❖ Since the architecture only predicts boxes, this might make it less useful for irregular shapes', metadata={'source': 'data/yolo.pdf'})]"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "docs"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **USING LLM MODEL**"
      ],
      "metadata": {
        "id": "jagmCK6x6mSi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SAiHxgysGrWX"
      },
      "outputs": [],
      "source": [
        "from langchain.chains.question_answering import load_qa_chain\n",
        "from langchain.llms import OpenAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GDfNPBH0GxE_"
      },
      "outputs": [],
      "source": [
        "# define chain\n",
        "chain = load_qa_chain(\n",
        "    OpenAI(openai_api_key = OPENAI_API_KEY,temperature=0),\n",
        "    chain_type=\"stuff\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**if temperature is 0 it is gives correct value**"
      ],
      "metadata": {
        "id": "_CTV4fbK6Xz4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "9wThVt_yG6tO",
        "outputId": "b8d886fa-9ad9-406a-9212-69d4ecf89544"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "' YOLO is an algorithm for object detection that is unified, real-time, and has high accuracy. It is presented by Shivang Singh in the CS391R: Robot Learning (Fall 2021) course on Sept 2nd, 2021.'"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# create answer\n",
        "chain.run(input_documents=docs, question=query)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}